{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\windo\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "from utils import load_face_landmark_model, load_fr_model, load_embeddings_model, load_face_detector, load_inv_label_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_landmarks_model = load_face_landmark_model()\n",
    "fr_model = load_fr_model()\n",
    "face_detector = load_face_detector()\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "svm = load_embeddings_model(model='svm')\n",
    "inv_label_dictionary = load_inv_label_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, img = cam.read()\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    faces = face_detector(gray, 1)\n",
    "    try:\n",
    "        for face_rect in faces:\n",
    "            x, y, w, h = face_rect.left(), face_rect.top(), face_rect.right(), face_rect.bottom()\n",
    "            cv2.rectangle(rgb,(x, y),(w, h),(0,255,0),2)\n",
    "\n",
    "            dlib_box = dlib.rectangle(x, y, w, h)\n",
    "\n",
    "            pose = face_landmarks_model(rgb, dlib_box)\n",
    "            encoding = np.array(fr_model.compute_face_descriptor(rgb, pose, 1))\n",
    "\n",
    "            name = svm.predict_proba([encoding])[0]\n",
    "            max_arg = name.argmax()\n",
    "            \n",
    "            label = \"Others\"\n",
    "            \n",
    "            if name[max_arg] > 0.96:\n",
    "                label = inv_label_dictionary[max_arg] + \": \" + str(round(name[max_arg] * 100, 2))\n",
    "                \n",
    "            cv2.putText(rgb, label, (x-10,y-10), font, 0.6, (255,255,0), 1, cv2.LINE_AA)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    \n",
    "    img = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imshow('img', img)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capture Image and Detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Prateek']\n"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "predictions = []\n",
    "while True:\n",
    "    ret, img = cam.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    if cv2.waitKey(1) == ord('c'):\n",
    "        try:\n",
    "            faces = face_detector(gray, 1)\n",
    "            for face_rect in faces:\n",
    "                x, y, w, h = face_rect.left(), face_rect.top(), face_rect.right(), face_rect.bottom()\n",
    "                cv2.rectangle(rgb,(x, y),(w, h),(0,255,0),2)\n",
    "                dlib_box = dlib.rectangle(x, y, w, h)\n",
    "                pose = face_landmarks_model(rgb, dlib_box)\n",
    "                embedding = np.array(fr_model.compute_face_descriptor(rgb, pose, 1))\n",
    "                name = svm.predict_proba([embedding])[0]\n",
    "\n",
    "                max_arg = name.argmax()\n",
    "                \n",
    "                label = \"Others\"\n",
    "                \n",
    "                if name[max_arg] > 0.96:\n",
    "                    predictions.append(inv_label_dictionary[max_arg])\n",
    "                    label = inv_label_dictionary[max_arg] + \": \" + str(round(name[max_arg] * 100, 2))\n",
    "                else:\n",
    "                    predictions.append(\"Others\")\n",
    "                \n",
    "                cv2.putText(rgb, label, (x-10,y-10), font, 0.6, (255, 255, 0), 1, cv2.LINE_AA)\n",
    "                                \n",
    "            break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "        \n",
    "    img = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imshow('img', img)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "img = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n",
    "cv2.imshow('output', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
